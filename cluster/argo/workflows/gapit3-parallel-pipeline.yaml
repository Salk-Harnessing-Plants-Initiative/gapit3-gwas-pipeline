apiVersion: argoproj.io/v1alpha1
kind: Workflow
metadata:
  generateName: gapit3-gwas-parallel-  # Argo appends unique suffix
  namespace: runai-talmo-lab
  labels:
    pipeline: gapit3-gwas
    stage: production
spec:
  # ===========================================================================
  # GAPIT3 GWAS - Full Parallel Pipeline (186 Traits)
  # ===========================================================================
  # Production workflow: runs all 186 traits in parallel
  # DAG structure: Validate → Extract → 186 parallel GWAS → Collect Results
  #
  # NOTE: Resource allocation (CPU, memory) is configured in WorkflowTemplate:
  #   cluster/argo/workflow-templates/gapit3-single-trait-template.yaml
  # ===========================================================================

  entrypoint: parallel-pipeline
  serviceAccountName: default

  # Workflow-level parameters
  arguments:
    parameters:
    - name: image
      value: "ghcr.io/salk-harnessing-plants-initiative/gapit3-gwas-pipeline:sha-834d729-test"
    - name: data-hostpath
      value: "/hpi/hpi_dev/users/eberrigan/20251208_Elohim_Bello_iron_deficiency_GAPIT_GWAS/data"
    - name: output-hostpath
      value: "/hpi/hpi_dev/users/eberrigan/20251208_Elohim_Bello_iron_deficiency_GAPIT_GWAS/outputs"
    - name: start-trait-index
      value: "2"      # First trait column (after Taxa)
    - name: end-trait-index
      value: "187"    # Last trait column (186 traits total)
    - name: models
      value: "BLINK,FarmCPU,MLM"
    - name: snp-fdr
      value: "0.05"  # 5% FDR threshold (Benjamini-Hochberg correction)

  # Global timeout (7 days - effectively no limit, can terminate manually if needed)
  activeDeadlineSeconds: 604800

  # Workflow-level volumes
  volumes:
  - name: nfs-data
    hostPath:
      path: "{{workflow.parameters.data-hostpath}}"
      type: Directory
  - name: nfs-outputs
    hostPath:
      path: "{{workflow.parameters.output-hostpath}}"
      type: DirectoryOrCreate

  templates:
  # ===========================================================================
  # Main DAG
  # ===========================================================================
  - name: parallel-pipeline
    dag:
      tasks:
      # Step 1: Validate inputs
      - name: validate-inputs
        template: validate

      # Step 2: Extract trait manifest
      - name: extract-traits
        dependencies: [validate-inputs]
        template: extract-traits-inline

      # Step 3: Run all traits in parallel (withSequence)
      - name: run-all-traits
        dependencies: [extract-traits]
        templateRef:
          name: gapit3-gwas-single-trait
          template: run-gwas
        arguments:
          parameters:
          - name: trait-index
            value: "{{item}}"
          - name: trait-name
            value: "trait-{{item}}"
          - name: image
            value: "{{workflow.parameters.image}}"
          - name: models
            value: "{{workflow.parameters.models}}"
          - name: snp-fdr
            value: "{{workflow.parameters.snp-fdr}}"
        withSequence:
          start: "{{workflow.parameters.start-trait-index}}"
          end: "{{workflow.parameters.end-trait-index}}"

      # Step 4: Collect and aggregate results (runs after all traits complete)
      - name: collect-results
        dependencies: [run-all-traits]
        templateRef:
          name: gapit3-results-collector
          template: collect-results
        arguments:
          parameters:
          - name: image
            value: "{{workflow.parameters.image}}"
          - name: output-hostpath
            value: "{{workflow.parameters.output-hostpath}}"
          - name: batch-id
            value: "{{workflow.name}}"

  # ===========================================================================
  # Template: Validation
  # ===========================================================================
  - name: validate
    container:
      image: "{{workflow.parameters.image}}"
      imagePullPolicy: Always
      command: ["/scripts/entrypoint.sh"]
      args: ["validate"]

      env:
      - name: GENOTYPE_FILE
        value: "/data/genotype/acc_snps_filtered_maf_perl_edited_diploid.hmp.txt"
      - name: PHENOTYPE_FILE
        value: "/data/phenotype/iron_traits_edited.txt"
      - name: ACCESSION_IDS_FILE
        value: "/data/metadata/ids_gwas.txt"

      volumeMounts:
      - name: nfs-data
        mountPath: /data
        readOnly: true

      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"

  # ===========================================================================
  # Template: Extract traits
  # ===========================================================================
  - name: extract-traits-inline
    container:
      image: "{{workflow.parameters.image}}"
      imagePullPolicy: Always
      command: ["/scripts/entrypoint.sh"]
      args:
        - "extract-traits"
        - "/data/phenotype/iron_traits_edited.txt"
        - "/outputs/traits_manifest.yaml"

      volumeMounts:
      - name: nfs-data
        mountPath: /data
        readOnly: true
      - name: nfs-outputs
        mountPath: /outputs

      resources:
        requests:
          memory: "2Gi"
          cpu: "1"
        limits:
          memory: "4Gi"
          cpu: "2"

  # ===========================================================================
  # Parallelism control
  # ===========================================================================
  # Limit concurrent pod execution to avoid overwhelming cluster
  # At peak: 30 jobs × 64GB = 1.9TB RAM, 30 jobs × 12 CPU = 360 CPUs
  parallelism: 30
